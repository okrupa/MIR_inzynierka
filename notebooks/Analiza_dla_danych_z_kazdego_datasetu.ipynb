{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2gWwzHWxLPA"
      },
      "source": [
        "##Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO3dUfvgxNfm"
      },
      "outputs": [],
      "source": [
        "sample_rate = 16000 # sample rate of the audio\n",
        "n_way= 3 # number of classes per episode\n",
        "n_support = 5 # number of support examples per class\n",
        "n_query = 20 # number of samples per class to use as query\n",
        "n_train_episodes = int(10000) # number of episodes to generate for training\n",
        "n_val_episodes = 50 # number of episodes to generate for validation\n",
        "num_workers = 10 # number of workers to use for data loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch\n",
        "!pip install pytorch-lightning\n",
        "!pip install numpy\n",
        "!pip install --no-cache-dir --upgrade music-fsl"
      ],
      "metadata": {
        "id": "_X_h2E-OHRJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FewShotLearner\n"
      ],
      "metadata": {
        "id": "Z8eBuNpbxDC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zogbiTncKgTV",
        "outputId": "f0475d83-42cb-4d3b-a633-e579c2f1fc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3FKt9ZrC93g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from typing import Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "from music_fsl.backbone import Backbone\n",
        "from music_fsl.protonet import PrototypicalNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdjHjTI1pm8O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "class ClassConditionalDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[Any, Any]:\n",
        "        \"\"\"\n",
        "        Grab an item from the dataset. The item returned must be a dictionary. \n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    @property\n",
        "    def classlist(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        The classlist property returns a list of class labels available in the dataset.\n",
        "        This property enables users of the dataset to easily access a list of all the classes in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            List[str]: A list of class labels available in the dataset. \n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def class_to_indices(self) -> Dict[str, List[int]]:\n",
        "        \"\"\"\n",
        "        Returns a dictionary where the keys are class labels and the values are \n",
        "        lists of indices in the dataset that belong to that class. \n",
        "        This property enables users of the dataset to easily access \n",
        "        examples that belong to specific classes. \n",
        "\n",
        "        Implement me!\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, List[int]]: A dictionary mapping class labels to lists of dataset indices. \n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import music_fsl.util as util\n",
        "\n",
        "from typing import Tuple, Dict\n",
        "class EpisodeDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "        A dataset for sampling few-shot learning tasks from a class-conditional dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (ClassConditionalDataset): The dataset to sample episodes from.\n",
        "        n_way (int): The number of classes to sample per episode.\n",
        "            Default: 5.\n",
        "        n_support (int): The number of samples per class to use as support.\n",
        "            Default: 5.\n",
        "        n_query (int): The number of samples per class to use as query.\n",
        "            Default: 20.\n",
        "        n_episodes (int): The number of episodes to generate.\n",
        "            Default: 100.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "        dataset: ClassConditionalDataset, \n",
        "        n_way: int = 5, \n",
        "        n_support: int = 5,\n",
        "        n_query: int = 20,\n",
        "        n_episodes: int = 100,\n",
        "    ):\n",
        "        self.dataset = dataset\n",
        "\n",
        "        self.n_way = n_way\n",
        "        self.n_support = n_support\n",
        "        self.n_query = n_query\n",
        "        self.n_episodes = n_episodes\n",
        "    \n",
        "    def __getitem__(self, index: int) -> Tuple[Dict, Dict]:\n",
        "        \"\"\"Sample an episode from the class-conditional dataset. \n",
        "\n",
        "        Each episode is a tuple of two dictionaries: a support set and a query set.\n",
        "        The support set contains a set of samples from each of the classes in the\n",
        "        episode, and the query set contains another set of samples from each of the\n",
        "        classes. The class labels are added to each item in the support and query\n",
        "        sets, and the list of classes is also included in each dictionary.\n",
        "\n",
        "        Yields:\n",
        "            Tuple[Dict[str, Any], Dict[str, Any]]: A tuple containing the support\n",
        "            set and the query set for an episode.\n",
        "        \"\"\"\n",
        "        # seed the random number generator so we can reproduce this episode\n",
        "        rng = random.Random(index)\n",
        "\n",
        "        # sample the list of classes for this episode\n",
        "        episode_classlist = rng.sample(self.dataset.classlist, self.n_way)\n",
        "\n",
        "        # sample the support and query sets for this episode\n",
        "        support, query = [], []\n",
        "        for c in episode_classlist:\n",
        "            # grab the dataset indices for this class\n",
        "            all_indices = self.dataset.class_to_indices[c]\n",
        "            # sample the support and query sets for this class\n",
        "            indices = rng.sample(all_indices, self.n_support + self.n_query)\n",
        "            items = [self.dataset[i] for i in indices]\n",
        "\n",
        "            # add the class label to each item\n",
        "            for item in items:\n",
        "                item[\"target\"] = torch.tensor(episode_classlist.index(c))\n",
        "\n",
        "            # split the support and query sets\n",
        "            support.extend(items[:self.n_support])\n",
        "            query.extend(items[self.n_support:])\n",
        "\n",
        "        # collate the support and query sets\n",
        "        support = util.collate_list_of_dicts(support)\n",
        "        query = util.collate_list_of_dicts(query)\n",
        "\n",
        "        support[\"classlist\"] = episode_classlist\n",
        "        query[\"classlist\"] = episode_classlist\n",
        "        \n",
        "        return support, query\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_episodes\n",
        "\n",
        "    def print_episode(self, support, query):\n",
        "        \"\"\"Print a summary of the support and query sets for an episode.\n",
        "\n",
        "        Args:\n",
        "            support (Dict[str, Any]): The support set for an episode.\n",
        "            query (Dict[str, Any]): The query set for an episode.\n",
        "        \"\"\"\n",
        "        print(\"Support Set:\")\n",
        "        print(f\"  Classlist: {support['classlist']}\")\n",
        "        print(f\"  Audio Shape: {support['audio'].shape}\")\n",
        "        print(f\"  Target Shape: {support['target'].shape}\")\n",
        "        print()\n",
        "        print(\"Query Set:\")\n",
        "        print(f\"  Classlist: {query['classlist']}\")\n",
        "        print(f\"  Audio Shape: {query['audio'].shape}\")\n",
        "        print(f\"  Target Shape: {query['target'].shape}\")\n"
      ],
      "metadata": {
        "id": "VP7GI6vxxXH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFRabyVEI34M"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torchmetrics import Accuracy\n",
        "# build models\n",
        "backbone = Backbone(sample_rate=sample_rate)\n",
        "protonet = PrototypicalNet(backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVCKcRVBI_cu"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FewShotLearner(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, \n",
        "        protonet: nn.Module, \n",
        "        learning_rate: float = 0.001,\n",
        "        # learning_rate: float = 1e-3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.protonet = protonet\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.metrics = nn.ModuleDict({\n",
        "            'accuracy': Accuracy()\n",
        "        })\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def step(self, batch, batch_idx, tag: str):\n",
        "        support, query = batch\n",
        "\n",
        "        logits = self.protonet(support, query)\n",
        "        loss = self.loss(logits, query[\"target\"])\n",
        "\n",
        "        output = {\"loss\": loss}\n",
        "        for k, metric in self.metrics.items():\n",
        "            output[k] = metric(logits, query[\"target\"])\n",
        "\n",
        "        for k, v in output.items():\n",
        "            self.log(f\"{k}/{tag}\", v)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx, \"train\")\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx, \"val\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yctwKz5DJCZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2e496c-a774-401b-8026-bca91063d9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'protonet' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['protonet'])`.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ],
      "source": [
        "learner = FewShotLearner(protonet)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TinySOL"
      ],
      "metadata": {
        "id": "KQqQYEyB04f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "class TinySOL(ClassConditionalDataset):\n",
        "    \"\"\"\n",
        "    Initialize a `TinySOL` dataset instance.\n",
        "\n",
        "    Args:\n",
        "        instruments (List[str]): A list of instruments to include in the dataset.\n",
        "        duration (float): The duration of each audio clip in the dataset (in seconds).\n",
        "        sample_rate (int): The sample rate of the audio clips in the dataset (in Hz).\n",
        "    \"\"\"\n",
        "\n",
        "    INSTRUMENTS = [\n",
        "        'Bassoon', 'Viola', 'Trumpet in C', 'Bass Tuba',\n",
        "        'Alto Saxophone', 'French Horn', 'Violin', \n",
        "        'Flute', 'Contrabass', 'Trombone', 'Cello', \n",
        "        'Clarinet in Bb', 'Oboe', 'Accordion'\n",
        "    ]\n",
        "\n",
        "    def __init__(self, \n",
        "            instruments: List[str] = None,\n",
        "            duration: float = 1.0, \n",
        "            sample_rate: int = 16000,\n",
        "            dataset_path: str = None\n",
        "        ):\n",
        "        if instruments is None:\n",
        "            instruments = self.INSTRUMENTS\n",
        "\n",
        "        self.instruments = instruments\n",
        "        self.duration = duration\n",
        "        self.sample_rate = sample_rate\n",
        "\n",
        "        # initialize the tinysol dataset\n",
        "        metadata = os.path.join(dataset_path, 'TinySOL_metadata.csv')\n",
        "        df = pd.read_csv(metadata) \n",
        "        paths = df.iloc[:, 0].apply(lambda x: os.path.join(dataset_path, x))\n",
        "        paths = paths.values.tolist()\n",
        "        labels = df.iloc[:, 4].values\n",
        "\n",
        "        # make sure the instruments passed in are valid\n",
        "        for instrument in instruments:\n",
        "            assert instrument in self.instruments, f\"{instrument} is not a valid instrument\"\n",
        "\n",
        "        # load all tracks for this instrument\n",
        "        self.tracks = []\n",
        "        for path, label in zip(paths, labels):\n",
        "            if label in self.instruments:\n",
        "              self.tracks.append([path, label])\n",
        "\n",
        "    @property\n",
        "    def classlist(self) -> List[str]:\n",
        "        return self.instruments\n",
        "\n",
        "    @property\n",
        "    def class_to_indices(self) -> Dict[str, List[int]]:\n",
        "        # cache it in self._class_to_indices \n",
        "        # so we don't have to recompute it every time\n",
        "        if not hasattr(self, \"_class_to_indices\"):\n",
        "            self._class_to_indices = defaultdict(list)\n",
        "            for i, track in enumerate(self.tracks):\n",
        "                self._class_to_indices[track[1]].append(i)\n",
        "\n",
        "        return self._class_to_indices\n",
        "\n",
        "    def __getitem__(self, index) -> Dict:\n",
        "        # load the track for this index\n",
        "        track = self.tracks[index]\n",
        "\n",
        "        # load the excerpt\n",
        "        data = util.load_excerpt(track[0], self.duration, self.sample_rate)\n",
        "        data[\"label\"] = track[1]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tracks)"
      ],
      "metadata": {
        "id": "k6MIXD9I0luf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_INSTRUMENTS = [\n",
        "    'French Horn', \n",
        "    'Violin', \n",
        "    'Flute', \n",
        "    'Contrabass', \n",
        "    'Trombone', \n",
        "    'Cello', \n",
        "    'Clarinet in Bb', \n",
        "    'Oboe',\n",
        "    'Accordion'\n",
        "]\n",
        "\n",
        "TEST_INSTRUMENTS = [\n",
        "    'Bassoon',\n",
        "    'Viola',\n",
        "    'Trumpet in C',\n",
        "    'Bass Tuba',\n",
        "    'Alto Saxophone'\n",
        "]"
      ],
      "metadata": {
        "id": "V2O6j2j50mSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GoodSounds"
      ],
      "metadata": {
        "id": "M2vz_8FX0r5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoodSounds(ClassConditionalDataset):\n",
        "    \"\"\"\n",
        "    Initialize a `GoodSounds Dataset Loader` dataset instance.\n",
        "    \n",
        "    Args:\n",
        "        instruments (List[str]): A list of instruments to include in the dataset.\n",
        "        duration (float): The duration of each audio clip in the dataset (in seconds).\n",
        "        sample_rate (int): The sample rate of the audio clips in the dataset (in Hz).\n",
        "        dataset - loaded mirdata.dataset\n",
        "    \"\"\"\n",
        "\n",
        "    INSTRUMENTS = [\n",
        "        'flute', 'cello', 'clarinet', 'trumpet', 'violin', 'sax_alto', 'sax_tenor', 'sax_baritone', 'sax_soprano', 'oboe', 'piccolo', 'bass'\n",
        "    ]\n",
        "\n",
        "    def __init__(self, \n",
        "            instruments: List[str] = None,\n",
        "            duration: float = 1.0, \n",
        "            sample_rate: int = 16000,\n",
        "            dataset_path: str = None\n",
        "        ):\n",
        "        if instruments is None:\n",
        "            instruments = self.INSTRUMENTS\n",
        "\n",
        "        self.instruments = instruments  \n",
        "        self.duration = duration\n",
        "        self.sample_rate = sample_rate\n",
        "        self.dataset_path = dataset_path\n",
        "\n",
        "        # make sure the instruments passed in are valid\n",
        "        for instrument in instruments:\n",
        "            assert instrument in self.INSTRUMENTS, f\"{instrument} is not a valid instrument\"\n",
        "\n",
        "        # load all tracks for this instrument\n",
        "        self.tracks = []\n",
        "        for dir in os.listdir(self.dataset_path):\n",
        "            ins = dir.split('_')[0]\n",
        "            if ins in self.instruments:\n",
        "                for subdir_dir, dirs_dir, files_dir in os.walk(os.path.join(self.dataset_path, dir, 'neumann')):\n",
        "                    for file in files_dir:\n",
        "                        if file.endswith('.wav'):\n",
        "                            if librosa.get_duration(filename=os.path.join(self.dataset_path, dir, 'neumann', file)) >= duration:\n",
        "                                self.tracks.append([os.path.join(self.dataset_path, dir, 'neumann', file), ins])\n",
        "            else:\n",
        "                ins = f'{ins}_{dir.split(\"_\")[1]}'\n",
        "                if ins in self.instruments:\n",
        "                    for subdir_dir, dirs_dir, files_dir in os.walk(os.path.join(self.dataset_path, dir, 'neumann')):\n",
        "                        for file in files_dir:\n",
        "                            if file.endswith('.wav'):\n",
        "                                if librosa.get_duration(filename=os.path.join(self.dataset_path, dir, 'neumann', file)) >= duration:\n",
        "                                    self.tracks.append([os.path.join(self.dataset_path, dir, 'neumann', file), ins])\n",
        "\n",
        "\n",
        "    @property\n",
        "    def classlist(self) -> List[str]:\n",
        "        return self.instruments\n",
        "\n",
        "    @property\n",
        "    def class_to_indices(self) -> Dict[str, List[int]]:\n",
        "        # cache it in self._class_to_indices \n",
        "        # so we don't have to recompute it every time\n",
        "        if not hasattr(self, \"_class_to_indices\"):\n",
        "            self._class_to_indices = defaultdict(list)\n",
        "            for i, track in enumerate(self.tracks):\n",
        "                self._class_to_indices[track[1]].append(i)\n",
        "\n",
        "        return self._class_to_indices\n",
        "\n",
        "    def __getitem__(self, index) -> Dict:\n",
        "        # load the track for this index\n",
        "        track = self.tracks[index]\n",
        "\n",
        "        # load the excerpt\n",
        "        data = util.load_excerpt(track[0], self.duration, self.sample_rate)\n",
        "        data[\"label\"] = track[1]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tracks)"
      ],
      "metadata": {
        "id": "qtdbZhNG0s_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TRAIN_INSTRUMENTS = [\n",
        "       'cello', 'clarinet', 'violin', 'sax_alto', 'sax_baritone', 'sax_soprano', 'piccolo',\n",
        "    ]\n",
        "\n",
        "TEST_INSTRUMENTS = [\n",
        "        'flute', 'trumpet', 'sax_tenor', 'oboe', 'bass'\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "i724dLiB0yxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDjc-BuDxR7A"
      },
      "source": [
        "##Medley_solos_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs5g37k5pjou"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "class MedleySolosDb(ClassConditionalDataset):\n",
        "    \"\"\"\n",
        "    Initialize a `Medley-solos-DB Dataset Loader` dataset instance.\n",
        "    \n",
        "     Each of these clips contains a single instrument among a taxonomy of eight:\n",
        "\n",
        "        0. clarinet,\n",
        "        1. distorted electric guitar,\n",
        "        2. female singer,\n",
        "        3. flute,\n",
        "        4. piano,\n",
        "        5. tenor saxophone,\n",
        "        6. trumpet, and\n",
        "        7. violin.\n",
        "\n",
        "    Args:\n",
        "        instruments (List[str]): A list of instruments to include in the dataset.\n",
        "        duration (float): The duration of each audio clip in the dataset (in seconds).\n",
        "        sample_rate (int): The sample rate of the audio clips in the dataset (in Hz).\n",
        "    \"\"\"\n",
        "\n",
        "    INSTRUMENTS = [\n",
        "        'clarinet',\n",
        "        'distorted electric guitar',\n",
        "        'female singer',\n",
        "        'flute',\n",
        "        'piano',\n",
        "        'tenor saxophone',\n",
        "        'trumpet',\n",
        "        'violin'\n",
        "    ]\n",
        "\n",
        "    def __init__(self, \n",
        "            instruments: List[str] = None,\n",
        "            duration: float = 1.0, \n",
        "            sample_rate: int = 16000,\n",
        "            dataset_path: str = None,\n",
        "        ):\n",
        "        if instruments is None:\n",
        "            instruments = self.INSTRUMENTS\n",
        "\n",
        "        self.instruments = instruments  \n",
        "        self.duration = duration\n",
        "        self.sample_rate = sample_rate\n",
        "\n",
        "        metadata = os.path.join(dataset_path, 'Medley-solos-DB_metadata.csv')\n",
        "        df = pd.read_csv(metadata) \n",
        "\n",
        "        # make sure the instruments passed in are valid\n",
        "        for instrument in instruments:\n",
        "            assert instrument in self.INSTRUMENTS, f\"{instrument} is not a valid instrument\"\n",
        "\n",
        "        # load all tracks for this instrument\n",
        "        self.tracks = []\n",
        "        for index, row in df.iterrows():\n",
        "            if row['instrument'] in self.instruments:\n",
        "                file_name = f'Medley-solos-DB_{row[\"subset\"]}-{row[\"instrument_id\"]}_{row[\"uuid4\"]}.wav.wav'\n",
        "                wav_file = os.path.join(dataset_path, 'Medley-solos-DB', file_name)\n",
        "                self.tracks.append([wav_file, row['instrument']])\n",
        "\n",
        "\n",
        "    @property\n",
        "    def classlist(self) -> List[str]:\n",
        "        return self.instruments\n",
        "\n",
        "    @property\n",
        "    def class_to_indices(self) -> Dict[str, List[int]]:\n",
        "        # cache it in self._class_to_indices \n",
        "        # so we don't have to recompute it every time\n",
        "        if not hasattr(self, \"_class_to_indices\"):\n",
        "            self._class_to_indices = defaultdict(list)\n",
        "            for i, track in enumerate(self.tracks):\n",
        "                self._class_to_indices[track[1]].append(i)\n",
        "\n",
        "        return self._class_to_indices\n",
        "\n",
        "    def __getitem__(self, index) -> Dict:\n",
        "        # load the track for this index\n",
        "        track = self.tracks[index]\n",
        "\n",
        "        # load the excerpt\n",
        "        data = util.load_excerpt(track[0], self.duration, self.sample_rate)\n",
        "        data[\"label\"] = track[1]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tracks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSc3wagoD32S"
      },
      "outputs": [],
      "source": [
        "TRAIN_INSTRUMENTS = [\n",
        "        'flute', 'piano', 'tenor saxophone', 'trumpet', 'violin'\n",
        "    ]\n",
        "\n",
        "TEST_INSTRUMENTS = [\n",
        "        'clarinet', 'distorted electric guitar', 'female singer',\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IRMAS"
      ],
      "metadata": {
        "id": "RyroZoD9xLLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import mirdata\n",
        "import music_fsl.util as util\n",
        "from typing import List, Dict\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "class IRMAS(ClassConditionalDataset):\n",
        "    \"\"\"\n",
        "    Initialize a `IRMAS` dataset instance.\n",
        "\n",
        "    Args:\n",
        "        instruments (List[str]): A list of instruments to include in the dataset.\n",
        "        duration (float): The duration of each audio clip in the dataset (in seconds).\n",
        "        sample_rate (int): The sample rate of the audio clips in the dataset (in Hz).\n",
        "    \"\"\"\n",
        "\n",
        "    INSTRUMENTS = [\n",
        "        'Cello', 'Clarinet', 'Flute', 'Acoustic guitar',\n",
        "        'Electric guitar', 'Organ', 'Piano', \n",
        "        'Saxophone', 'Trumpet', 'Violin', 'Human singing voice'\n",
        "    ]\n",
        "\n",
        "    INSTRUMENTS_KEY = {\n",
        "        'cel': 'Cello', 'cla' : 'Clarinet', 'flu' : 'Flute', 'gac' : 'Acoustic guitar',\n",
        "        'gel' : 'Electric guitar', 'org' : 'Organ', 'pia' : 'Piano', \n",
        "        'sax' : 'Saxophone', 'tru' : 'Trumpet', 'vio' : 'Violin', 'voi' : 'Human singing voice'\n",
        "    }\n",
        "    def __init__(self, \n",
        "            instruments: List[str] = None,\n",
        "            instruments_key: Dict[str, str] = None,\n",
        "            duration: float = 1.0, \n",
        "            sample_rate: int = 16000,\n",
        "            dataset_path: str = 'irmas',\n",
        "            val = False,\n",
        "        ):\n",
        "        if instruments_key is None:\n",
        "            instruments_key = self.INSTRUMENTS_KEY\n",
        "\n",
        "        if instruments is None:\n",
        "            instruments = self.INSTRUMENTS\n",
        "\n",
        "        if val == False and dataset_path == 'irmas':\n",
        "            dir_path = os.path.dirname(os.path.realpath(__file__))\n",
        "            dataset_path = os.path.join(os.path.dirname(dir_path), dataset_path)\n",
        "        \n",
        "\n",
        "        self.instruments = instruments\n",
        "        self.instruments_key = instruments_key\n",
        "        self.duration = duration\n",
        "        self.sample_rate = sample_rate\n",
        "\n",
        "        # initialize IRMAS path \n",
        "        if val == False:\n",
        "          if os.path.exists(dataset_path):\n",
        "            self.dataset_path = dataset_path\n",
        "          else:\n",
        "            sys.exit(\"Dataset path does not exist\")\n",
        "        \n",
        "        if val:\n",
        "          self.dataset_path = dataset_path\n",
        "\n",
        "        # make sure the instruments passed in are valid\n",
        "        for instrument in instruments:\n",
        "            assert instrument in self.INSTRUMENTS, f\"{instrument} is not a valid instrument\"\n",
        "\n",
        "        # load all tracks for this instrument\n",
        "        if val:\n",
        "            self.load_all_tracks_val()\n",
        "        else:\n",
        "            self.load_all_tracks()\n",
        "\n",
        "\n",
        "    def load_all_tracks(self):\n",
        "        self.tracks = []\n",
        "        for subdir, dirs, files in os.walk(self.dataset_path):\n",
        "            for dir in dirs:\n",
        "                if dir in self.instruments_key.keys():\n",
        "                    for subdir_dir, dirs_dir, files_dir in os.walk(os.path.join(subdir, dir)):\n",
        "                        for file in files_dir:\n",
        "                            self.tracks.append([os.path.join(subdir, dir, file), self.instruments_key[dir]])\n",
        "\n",
        "    def load_all_tracks_val(self):\n",
        "        self.tracks = []\n",
        "        for paths in self.dataset_path:\n",
        "          for subdir, dirs, files in os.walk(paths, topdown=True):\n",
        "              for file in sorted(files)[::2]:\n",
        "                  f = open(os.path.join(subdir, file), \"rb\")\n",
        "                  tags = f.readlines()\n",
        "                  for tag in tags:\n",
        "                      tag = tag[:3].decode(\"utf-8\") \n",
        "                      f.close()\n",
        "                      if tag in self.instruments_key.keys():\n",
        "                          wav_file = os.path.join(subdir, file).replace('.txt', '.wav')\n",
        "                          if os.path.exists(wav_file):\n",
        "                            self.tracks.append([wav_file, self.instruments_key[tag]])\n",
        "\n",
        "    @property\n",
        "    def classlist(self) -> List[str]:\n",
        "        return self.instruments\n",
        "\n",
        "    @property\n",
        "    def class_to_indices(self) -> Dict[str, List[int]]:\n",
        "        # cache it in self._class_to_indices \n",
        "        # so we don't have to recompute it every time\n",
        "        if not hasattr(self, \"_class_to_indices\"):\n",
        "            self._class_to_indices = defaultdict(list)\n",
        "            for i, track in enumerate(self.tracks):\n",
        "                self._class_to_indices[track[1]].append(i)\n",
        "\n",
        "        return self._class_to_indices\n",
        "\n",
        "    def __getitem__(self, index) -> Dict:\n",
        "        # load the track for this index\n",
        "        track = self.tracks[index]\n",
        "\n",
        "        # load the excerpt\n",
        "        data = util.load_excerpt(track[0], self.duration, self.sample_rate)\n",
        "        data[\"label\"] = track[1]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tracks)"
      ],
      "metadata": {
        "id": "gjyQ3UPnKQVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_INSTRUMENTS = [\n",
        "        'Flute', 'Organ', 'Saxophone',\n",
        "        'Trumpet', 'Violin', 'Electric guitar'\n",
        "    ]\n",
        "\n",
        "TRAIN_INSTRUMENTS_KEY = {\n",
        "        'flu' : 'Flute', 'org' : 'Organ',\n",
        "        'sax' : 'Saxophone', 'tru' : 'Trumpet', 'vio' : 'Violin', 'gel' : 'Electric guitar'\n",
        "    }\n",
        "\n",
        "TEST_INSTRUMENTS = [\n",
        "        'Cello', 'Piano', 'Clarinet', 'Acoustic guitar', 'Human singing voice'\n",
        "    ]\n",
        "\n",
        "TEST_INSTRUMENTS_KEY = {\n",
        "        'cel': 'Cello', 'gac' : 'Acoustic guitar', 'pia' : 'Piano',  'voi' : 'Human singing voice', 'cla' : 'Clarinet'\n",
        "    }"
      ],
      "metadata": {
        "id": "KcudyOr2KRpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrSDE4rSzZU4"
      },
      "source": [
        "#Data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare choosen models (for 3-way and 5-way)"
      ],
      "metadata": {
        "id": "k5Pv3xKYx5zF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PlvmHFPI1tA",
        "outputId": "88c431ad-860d-4d00-af1d-2353445c2bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/irmas_3_5_1000.zip\n",
            "   creating: /content/3_5_irmas/content/logs/\n",
            "   creating: /content/3_5_irmas/content/logs/version_1/\n",
            "  inflating: /content/3_5_irmas/content/logs/version_1/events.out.tfevents.1674778842.e98b3886b3c5.5426.1  \n",
            "   creating: /content/3_5_irmas/content/logs/version_1/checkpoints/\n",
            "  inflating: /content/3_5_irmas/content/logs/version_1/checkpoints/epoch=0-step=1000.ckpt  \n",
            "  inflating: /content/3_5_irmas/content/logs/version_1/fit-profile.txt.txt  \n",
            "  inflating: /content/3_5_irmas/content/logs/version_1/hparams.yaml  \n",
            "   creating: /content/3_5_irmas/content/logs/version_2/\n",
            "  inflating: /content/3_5_irmas/content/logs/version_2/events.out.tfevents.1674788703.e98b3886b3c5.5426.2  \n",
            "   creating: /content/3_5_irmas/content/logs/version_2/checkpoints/\n",
            "  inflating: /content/3_5_irmas/content/logs/version_2/checkpoints/epoch=0-step=1000.ckpt  \n",
            "  inflating: /content/3_5_irmas/content/logs/version_2/fit-profile.txt.txt  \n",
            "  inflating: /content/3_5_irmas/content/logs/version_2/hparams.yaml  \n",
            "   creating: /content/3_5_irmas/content/logs/version_0/\n",
            "  inflating: /content/3_5_irmas/content/logs/version_0/hparams.yaml  \n",
            "  inflating: /content/3_5_irmas/content/logs/version_0/events.out.tfevents.1674778509.e98b3886b3c5.5426.0  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/irmas_3_5_1000.zip -d /content/3_5_irmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcaDKdRAI59P",
        "outputId": "f388a649-5cb5-48fe-a353-a47b20f8ec5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/irmas_5_5_1000.zip\n",
            "   creating: /content/5_5_irmas/content/logs/\n",
            "   creating: /content/5_5_irmas/content/logs/version_0/\n",
            "  inflating: /content/5_5_irmas/content/logs/version_0/hparams.yaml  \n",
            "  inflating: /content/5_5_irmas/content/logs/version_0/events.out.tfevents.1674778509.e98b3886b3c5.5426.0  \n",
            "   creating: /content/5_5_irmas/content/logs/version_1/\n",
            "  inflating: /content/5_5_irmas/content/logs/version_1/events.out.tfevents.1674778842.e98b3886b3c5.5426.1  \n",
            "   creating: /content/5_5_irmas/content/logs/version_1/checkpoints/\n",
            "  inflating: /content/5_5_irmas/content/logs/version_1/checkpoints/epoch=0-step=1000.ckpt  \n",
            "  inflating: /content/5_5_irmas/content/logs/version_1/fit-profile.txt.txt  \n",
            "  inflating: /content/5_5_irmas/content/logs/version_1/hparams.yaml  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/irmas_5_5_1000.zip -d /content/5_5_irmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVXqQNaInsNO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"torchmetrics==0.10.2\" \n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqoaL5_MoIzX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from music_fsl.util import dim_reduce, embedding_plot, batch_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--U183PwoQ1s"
      },
      "outputs": [],
      "source": [
        "checkpoint_path_5 = \"/content/5_5_irmas/content/logs/version_1/checkpoints/epoch=0-step=1000.ckpt\"\n",
        "checkpoint_path_3 = \"/content/3_5_irmas/content/logs/version_2/checkpoints/epoch=0-step=1000.ckpt\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sample_rate = 16000"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6llRH3ixbFMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW4fE_3foV7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd27650-d367-4e37-cfaa-936d56c038d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'protonet' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['protonet'])`.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ],
      "source": [
        "protonet = PrototypicalNet(Backbone(sample_rate))\n",
        "learner_5 = FewShotLearner.load_from_checkpoint(checkpoint_path_5, protonet=protonet)\n",
        "learner_5.eval()\n",
        "learner_5 = learner_5.to(DEVICE)\n",
        "\n",
        "learner_3 = FewShotLearner.load_from_checkpoint(checkpoint_path_3, protonet=protonet)\n",
        "learner_3.eval()\n",
        "learner_3 = learner_3.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the datasets\n",
        "\n",
        "dataset_withcut = IRMAS(\n",
        "    instruments=TEST_INSTRUMENTS, \n",
        "    instruments_key = TEST_INSTRUMENTS_KEY,\n",
        "    sample_rate=sample_rate,\n",
        "    dataset_path = '/content/drive/MyDrive/irmas/training/IRMAS-TrainingData'\n",
        ")"
      ],
      "metadata": {
        "id": "9V5KmAlxKTNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l539ifqmoYEf"
      },
      "outputs": [],
      "source": [
        "n_query = 15"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=3 \n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "R-qx--VTDA_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metric"
      ],
      "metadata": {
        "id": "VPM4VDrQJ5HC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9rmF4QRolii"
      },
      "outputs": [],
      "source": [
        "metric_3 = Accuracy(num_classes=n_way, average=\"samples\")\n",
        "metric_5 = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3waytrain_3waytest\n"
      ],
      "metadata": {
        "id": "-7dTbCQiJ_03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table_3 = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner_3.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric_3(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table_3.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table_3.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "a_63cG9aJ-2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "0ZN0uixnQUb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels([TEST_INSTRUMENTS)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-gURFrn9Qbyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_acc = metric_3.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "et-JgWoeQcvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5waytrain_3waytest\n"
      ],
      "metadata": {
        "id": "qbvxiGCUP36P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table_5 = []\n",
        "y_act_5, y_pred_5 = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner_3.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act_5.extend(query_target)\n",
        "    outputs = softmax(logits)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred_5.extend(predicted_s)\n",
        "    acc = metric_5(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table_5.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table_5.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "c3tsLQUCP5s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act_5, y_pred_5, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act_5, y_pred_5, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "iR2gUU2_P8Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix_5 = metrics.confusion_matrix(y_act_5, y_pred_5, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix_5, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZSZLC_y4QAfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric_5.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "RBjKXPKpQApx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For 5-way train"
      ],
      "metadata": {
        "id": "E32Oqg0gS6BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=5\n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "2mVbELlDS8U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQva9CxhS8j6"
      },
      "outputs": [],
      "source": [
        "metric_3 = Accuracy(num_classes=n_way, average=\"samples\")\n",
        "metric_5 = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3waytrain_5waytest"
      ],
      "metadata": {
        "id": "96Dy4zZBS8j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table_3 = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner_3.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric_3(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table_3.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table_3.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "9tIgJIl_S8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "Mv2IV2YFS8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7Nw9BZ_4S8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric_3.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "5nHqP0MPS8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5waytrain_5waytest\n"
      ],
      "metadata": {
        "id": "-NUuehmnS8j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table_5 = []\n",
        "y_act_5, y_pred_5 = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner_3.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act_5.extend(query_target)\n",
        "    outputs = softmax(logits)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred_5.extend(predicted_s)\n",
        "    acc = metric_5(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table_5.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table_5.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "ip1_hmmLS8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act_5, y_pred_5, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act_5, y_pred_5, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "mfNYyEjiS8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix_5 = metrics.confusion_matrix(y_act_5, y_pred_5, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix_5, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2u9uLfn7S8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric_5.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "CnU2SCIKS8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goodsounds\n"
      ],
      "metadata": {
        "id": "6SFVOORFml4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/filegoodsounds01.zip -d /content/Goodsouns"
      ],
      "metadata": {
        "id": "PMynYcEWmnSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_path = \"/content/Goodsouns/content/logs/version_1/checkpoints/epoch=0-step=1000.ckpt\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sample_rate = 16000\n",
        "\n",
        "protonet = PrototypicalNet(Backbone(sample_rate))\n",
        "learner = FewShotLearner.load_from_checkpoint(checkpoint_path, protonet=protonet)\n",
        "learner.eval()\n",
        "learner = learner.to(DEVICE)"
      ],
      "metadata": {
        "id": "-21U-cjioV7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=3\n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "6J33eKnvmnaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metric"
      ],
      "metadata": {
        "id": "p_yfruP4mnaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niYHwsm7mnaT"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3\n"
      ],
      "metadata": {
        "id": "sivXjfShmnaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "f_n9UdECmnaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "OXvJmMOimnaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3EfJiNAimnaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "Ha9LNB_8mnaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For 5-way train"
      ],
      "metadata": {
        "id": "WkWCOd5imnaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=5\n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "9vUoAM0QmnaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgf7KjznmnaV"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5\n"
      ],
      "metadata": {
        "id": "9Ud-dNknmnaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "v184ncOQmnaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "uSrCessYmnaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nuhRsYfPmnaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "ca9XAc-QmnaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#iRMAS"
      ],
      "metadata": {
        "id": "pm0hJJHQo7fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/irmas_5_5_1000.zip -d /content/IRMAS"
      ],
      "metadata": {
        "id": "XhW37Vw-o86n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_path = \"/content/IRMAS/content/logs/version_1/checkpoints/epoch=0-step=1000.ckpt\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sample_rate = 16000\n",
        "\n",
        "protonet = PrototypicalNet(Backbone(sample_rate))\n",
        "learner = FewShotLearner.load_from_checkpoint(checkpoint_path, protonet=protonet)\n",
        "learner.eval()\n",
        "learner = learner.to(DEVICE)"
      ],
      "metadata": {
        "id": "CUBXSLewo86o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=3 \n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "ZWLkQnDCo86o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metric"
      ],
      "metadata": {
        "id": "rOyLrKPNo86o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzW-xK1vo86o"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3\n"
      ],
      "metadata": {
        "id": "NTI3DKxEo86o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "W4z7AI-Ho86o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "bVuMKk_wo86p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "saP4D8A4o86p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "64b3LAYoo86p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For 5-way train"
      ],
      "metadata": {
        "id": "LgSkwof9o86q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=5\n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "KPt2vtsQo86q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbTn78g6o86q"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5\n"
      ],
      "metadata": {
        "id": "ygKRp3QWo86q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "EyQUFPBIo86q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "296F_Q4no86q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dCziQvy2o86q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "07Z5XJ5Eo86q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TinySOL\n"
      ],
      "metadata": {
        "id": "0POAoAeko3qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/tinysol_5_5_1000_001_1s.zip -d /content/TINYSOL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHIjlTiko6Dr",
        "outputId": "affe2745-d5b2-4ada-bef5-d891371824e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/tinysol_5_5_1000_001_1s.zip\n",
            "   creating: /content/TINYSOL/content/logs/\n",
            "   creating: /content/TINYSOL/content/logs/version_0/\n",
            "  inflating: /content/TINYSOL/content/logs/version_0/events.out.tfevents.1674613023.4f5b1a403261.2978.0  \n",
            "  inflating: /content/TINYSOL/content/logs/version_0/hparams.yaml  \n",
            "  inflating: /content/TINYSOL/content/logs/version_0/fit-profile.txt.txt  \n",
            "   creating: /content/TINYSOL/content/logs/version_0/checkpoints/\n",
            "  inflating: /content/TINYSOL/content/logs/version_0/checkpoints/epoch=0-step=1000.ckpt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_path = \"/content/TINYSOL/content/logs/version_0/checkpoints/epoch=0-step=1000.ckpt\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sample_rate = 16000\n",
        "\n",
        "protonet = PrototypicalNet(Backbone(sample_rate))\n",
        "learner = FewShotLearner.load_from_checkpoint(checkpoint_path, protonet=protonet)\n",
        "learner.eval()\n",
        "learner = learner.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272db97a-c3ac-46ee-8a48-320abf913617",
        "id": "lYY04Do1o6Dr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'protonet' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['protonet'])`.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=3 \n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "_VszXuf8o6Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metric"
      ],
      "metadata": {
        "id": "Ziv6ZUOmo6Ds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuPri52No6Ds"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3\n"
      ],
      "metadata": {
        "id": "9Pcbr_Avo6Ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02336176-df10-4128-d2af-ac5e5dfdcb85",
        "id": "-NkffX_mo6Ds"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-86-3329f8b0b161>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  outputs = softmax(logits)\n",
            "Episode 99 // Accuracy: 0.60: 100%|| 100/100 [02:39<00:00,  1.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "c9nEeGRXo6Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2P_GCDO2o6Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "O06rLK1uo6Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For 5-way train"
      ],
      "metadata": {
        "id": "6LH2ujtro6Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=5\n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "8SbMcXINo6Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKyFw0Auo6Dt"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5\n"
      ],
      "metadata": {
        "id": "WhpmaOuBo6Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "2XEr4y1Bo6Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=TEST_INSTRUMENTS))"
      ],
      "metadata": {
        "id": "1EeV0qAJo6Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=TEST_INSTRUMENTS)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "ax.yaxis.set_ticklabels(TEST_INSTRUMENTS)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YqgrDwOto6Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "-n0kMXXXo6Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MadleySolosDB"
      ],
      "metadata": {
        "id": "wcIIw-y0z_b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/medley_solos_db_3_5_001_1000.zip -d /content/MADLEY"
      ],
      "metadata": {
        "id": "EgTLFaI7z_b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_path = \"/content/MADLEY/content/logs/version_4/checkpoints/epoch=0-step=1000.ckpt\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sample_rate = 16000\n",
        "\n",
        "protonet = PrototypicalNet(Backbone(sample_rate))\n",
        "learner = FewShotLearner.load_from_checkpoint(checkpoint_path, protonet=protonet)\n",
        "learner.eval()\n",
        "learner = learner.to(DEVICE)"
      ],
      "metadata": {
        "id": "-oowzIFFz_b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=3 \n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "pC2xUDX2z_b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metric"
      ],
      "metadata": {
        "id": "P0H6s19Iz_b7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy0klAbrz_b7"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3\n"
      ],
      "metadata": {
        "id": "XoNUWjJuz_b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "OrovqdVlz_b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass']))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass']))"
      ],
      "metadata": {
        "id": "YtX7Brsrz_b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass'])\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass'])\n",
        "ax.yaxis.set_ticklabels(['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ktoYjfMkz_b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "ksGKH0smz_b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For 5-way train"
      ],
      "metadata": {
        "id": "neeSNdPdz_b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load our evaluation data\n",
        "n_way=5\n",
        "n_support=5\n",
        "n_episodes = 100 \n",
        "\n",
        "test_episodes = EpisodeDataset(\n",
        "    dataset=dataset_withcut, \n",
        "    n_way=n_way, \n",
        "    n_support=n_support,\n",
        "    n_query=n_query, \n",
        "    n_episodes=n_episodes\n",
        ")"
      ],
      "metadata": {
        "id": "pWott4hEz_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCq3lNBvz_b8"
      },
      "outputs": [],
      "source": [
        "metric = Accuracy(num_classes=n_way, average=\"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5\n"
      ],
      "metadata": {
        "id": "S8tCyIVwz_b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all the embeddings in the test set\n",
        "# so we can plot them later\n",
        "from torch import nn\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "embedding_table = []\n",
        "y_act, y_pred = [], []\n",
        "\n",
        "pbar = tqdm.tqdm(range(len(test_episodes)))\n",
        "for episode_idx in pbar:\n",
        "    support, query = test_episodes[episode_idx]\n",
        "\n",
        "    # move all tensors to cuda if necessary\n",
        "    batch_device(support, DEVICE)\n",
        "    batch_device(query, DEVICE)\n",
        "\n",
        "    # get the embeddings\n",
        "    logits = learner.protonet(support, query)\n",
        "\n",
        "    # compute the accuracy\n",
        "    query_target = [support[\"classlist\"][i] for i in query[\"target\"]]\n",
        "    y_act.extend(query_target)\n",
        "\n",
        "    outputs = softmax(logits)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_s = [support[\"classlist\"][i] for i in predicted]\n",
        "    y_pred.extend(predicted_s)\n",
        "    acc = metric(logits, query[\"target\"])\n",
        "    pbar.set_description(f\"Episode {episode_idx} // Accuracy: {acc.item():.2f}\")\n",
        "    # add all the support and query embeddings to our records\n",
        "    for subset_idx, subset in enumerate((support, query)):\n",
        "        for emb, label in zip(subset[\"embeddings\"], subset[\"target\"]):\n",
        "            embedding_table.append({\n",
        "                \"embedding\": emb.detach().cpu().numpy(),\n",
        "                \"label\": support[\"classlist\"][label],\n",
        "                \"marker\": (\"support\", \"query\")[subset_idx], \n",
        "                \"episode_idx\": episode_idx\n",
        "            })\n",
        "        \n",
        "    # also add the prototype embeddings to our records\n",
        "    for class_idx, emb in enumerate(support[\"prototypes\"]):\n",
        "        embedding_table.append({\n",
        "            \"embedding\": emb.detach().cpu().numpy(),\n",
        "            \"label\": support[\"classlist\"][class_idx],\n",
        "            \"marker\": \"prototype\", \n",
        "            \"episode_idx\": episode_idx\n",
        "        })"
      ],
      "metadata": {
        "id": "uErFOaInz_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass']))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass']))"
      ],
      "metadata": {
        "id": "u0J1KBQ4z_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cf_matrix = metrics.confusion_matrix(y_act, y_pred, labels=['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass'])\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, )\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass'])\n",
        "ax.yaxis.set_ticklabels(['flute', 'trumpet', 'sax_tenor', 'sax_alto', 'bass'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E6A_gV6Hz_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the total accuracy across all episodes\n",
        "total_acc = metric.compute()\n",
        "print(f\"Total accuracy, averaged across all episodes: {total_acc:.2f}\")"
      ],
      "metadata": {
        "id": "Ckk5d1CZz_b8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "d2gWwzHWxLPA",
        "Z8eBuNpbxDC-",
        "KQqQYEyB04f1",
        "M2vz_8FX0r5x",
        "IDjc-BuDxR7A",
        "RyroZoD9xLLg",
        "yrSDE4rSzZU4",
        "VPM4VDrQJ5HC",
        "E32Oqg0gS6BE",
        "-NUuehmnS8j8",
        "6SFVOORFml4v",
        "pm0hJJHQo7fA",
        "0POAoAeko3qM",
        "wcIIw-y0z_b6"
      ]
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}